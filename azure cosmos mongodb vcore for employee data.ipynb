{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb0fe56",
   "metadata": {},
   "source": [
    "## Azure OpenAI <a class=\"anchor\" id=\"azureopenai\"></a>\n",
    "\n",
    "Finally, let's setup our Azure OpenAI resource Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at https://aka.ms/oai/access. Once you have access, complete the following steps:\n",
    "\n",
    "- Create an Azure OpenAI resource following this quickstart: https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal\n",
    "- Deploy a `completions` and `embeddings` model \n",
    "    - For more information on `completions`, go here: https://learn.microsoft.com/azure/ai-services/openai/how-to/completions\n",
    "    - For more information on `embeddings`, go here: https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings\n",
    "- Copy the endpoint, key, deployment names for (embeddings model, completions model) into the config.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8f571",
   "metadata": {},
   "source": [
    "## Create an Azure Cosmos DB for MongoDB vCore resource<a class=\"anchor\" id=\"cosmosdb\"></a>\n",
    "Let's start by creating an Azure Cosmos DB for MongoDB vCore Resource following this quick start guide: https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/quickstart-portal\n",
    "\n",
    "Then copy the connection details (server, user, pwd) into the config.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2ab9a",
   "metadata": {},
   "source": [
    "# Preliminaries <a class=\"anchor\" id=\"preliminaries\"></a>\n",
    "First, let's start by installing the packages that we'll need later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy\n",
    "! pip install openai==1.2.3\n",
    "! pip install pymongo\n",
    "! pip install python-dotenv\n",
    "! pip install azure-core\n",
    "! pip install azure-cosmos\n",
    "! pip install tenacity\n",
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "#You can use .env file. It will give you more security.\n",
    "openai.api_type = \"\"\n",
    "openai.api_key = \"\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai.api_key,\n",
    "    api_version=openai.api_version,\n",
    "    azure_endpoint = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b38477",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Load data and create embeddings <a class=\"anchor\" id=\"loaddata\"></a>\n",
    "Here we'll load a sample dataset containing descriptions of Azure services. Then we'll user Azure OpenAI to create vector embeddings from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text, model=\"text-embedding\")\n",
    "        embeddings = response.data[0].embedding\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred: [e]\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "embeddings = generate_embeddings(\"K.Shreekar Patra\")\n",
    "\n",
    "if embeddings is not None:\n",
    "    print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding data. Change the product item details as per your data\n",
    "\n",
    "import json\n",
    "\n",
    "# Load data from JSON file\n",
    "data_file_path = \"import your json format of your CSV\"\n",
    "with open(data_file_path, \"r\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "n = 0\n",
    "total_items = len(data)\n",
    "for item in data:  # Iterate directly over the list of shoe items\n",
    "    n += 1\n",
    "    product_string = f\"EMP ID: {row['EMP ID']}\" + \\\n",
    "                    (f\", NAME: {row['NAME']}\" if row['NAME'] else \"\") + \\\n",
    "                    (f\", DEPT: {row['DEPT']}\" if row['DEPT'] else \"\")\n",
    "    \n",
    "    # Assuming generate_embeddings is defined elsewhere\n",
    "    title_embeddings = generate_embeddings(product_string)\n",
    "    item['contentVector'] = title_embeddings\n",
    "    print(f\"Creating embeddings for item: {n}/{total_items}\", end='\\r')\n",
    "\n",
    "# Save embeddings to output_embeddings.json file\n",
    "output_file_path = \"path/output_embeddings.json\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(data, f, indent=1)\n",
    "\n",
    "print(\"\\nEmbeddings generation completed. Output saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "def csv_to_json_complete(input_csv_file, output_json_file):\n",
    "    # Open the CSV file for reading\n",
    "\n",
    "    daliClient = OpenAI(\n",
    "        api_key=config['dali_api_key']\n",
    "    )\n",
    "\n",
    "    with open(input_csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a CSV reader object\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Initialize an empty list to hold all the JSON objects\n",
    "        json_list = []\n",
    "        \n",
    "        # Initialize an ID counter starting at 1\n",
    "        auto_id = 1\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Add the 'id' key with an auto-incremented value\n",
    "\n",
    "            if auto_id > 300:\n",
    "                break\n",
    "\n",
    "            row['id'] = auto_id\n",
    "            # Convert string representations of boolean and None types to actual boolean and None types\n",
    "            for key, value in row.items():\n",
    "                if value == 'true': \n",
    "                    row[key] = True\n",
    "                elif value == 'false': \n",
    "                    row[key] = False\n",
    "                elif value == '':\n",
    "                    row[key] = None  # Convert empty strings to None\n",
    "\n",
    "            product_string = f\"EMP ID: {row['EMP ID']}\" + \\\n",
    "                    (f\", NAME: {row['NAME']}\" if row['NAME'] else \"\") + \\\n",
    "                    (f\", DEPT: {row['DEPT']}\" if row['DEPT'] else \"\")\n",
    "\n",
    "    # Open the JSON file for writing\n",
    "    with open(output_json_file, 'w', encoding='utf-8') as jsonfile:\n",
    "        # Write the list of JSON objects to the file\n",
    "        json.dump(json_list, jsonfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_csv_file = r\"path\\employee.csv\"  # Replace with your actual input CSV file path\n",
    "output_json_file = r\"path\\output_embeddings.json\"  # Replace with your actual output JSON file path\n",
    "# csv_to_json_complete(input_csv_file, output_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22da9b0",
   "metadata": {},
   "source": [
    "# Connect and setup Cosmos DB for MongoDB vCore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549a407",
   "metadata": {},
   "source": [
    "### Create database, collection, vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATA BASE ALSO CREATE VECTORE INDEX\n",
    "from pymongo import MongoClient\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Username and password\n",
    "username = \"your data base name\"\n",
    "password = \"your data base password\"\n",
    "\n",
    "# Escape username and password\n",
    "escaped_username = quote_plus(username)\n",
    "escaped_password = quote_plus(password)\n",
    "\n",
    "# Connection String\n",
    "mongo_conn = f\"YOUR CONNECTION STRING\"\n",
    "\n",
    "# Create MongoClient instance\n",
    "mongo_client = MongoClient(mongo_conn)\n",
    "\n",
    "# Database and Collection names\n",
    "DATABASE_NAME = \"Smart-ai\"\n",
    "COLLECTION_NAME = \"mongodb\"\n",
    "\n",
    "# Access or create the database\n",
    "db = mongo_client[DATABASE_NAME]\n",
    "\n",
    "# Check if the collection already exists\n",
    "if COLLECTION_NAME not in db.list_collection_names():\n",
    "    # Create the collection\n",
    "    collection = db.create_collection(COLLECTION_NAME)\n",
    "    print(\"Created collection '{}'.\".format(COLLECTION_NAME))\n",
    "else:\n",
    "    # Use the existing collection\n",
    "    collection = db[COLLECTION_NAME]\n",
    "    print(\"Using existing collection: '{}'.\".format(COLLECTION_NAME))\n",
    "\n",
    "# Create the vector index\n",
    "db.command({\n",
    "  'createIndexes': COLLECTION_NAME,\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'vectorSearchIndex',\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "print(\"Vector index created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55346f",
   "metadata": {},
   "source": [
    "## Upload data to the collection\n",
    "A simple `insert_many()` to insert our data in JSON format into the newly created DB and collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(file=\"PATH/output_embeddings.json\", mode=\"r\") \n",
    "data = json.load(data_file)\n",
    "data_file.close()\n",
    "\n",
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d6dc9",
   "metadata": {},
   "source": [
    "# Vector Search in Cosmos DB for MongoDB vCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f733a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to assist with vector search\n",
    "def vector_search(query, num_results=3):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    embeddings_list = []\n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"numLists\": 1,\n",
    "                    \"path\": \"contentVector\",\n",
    "                    \"k\": num_results\n",
    "                },\n",
    "                \"returnStoredSource\": True }},\n",
    "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d80d9",
   "metadata": {},
   "source": [
    "## Perform vector search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"List out the employees, who all are working in IT department\"\n",
    "results = vector_search(query, 5)\n",
    "for result in results: \n",
    "    print(f\"Similarity Score: {result['similarityScore']}\")  \n",
    "    print(f\"Title: {result['document']['EMP ID']}\")  \n",
    "    print(f\"Name: {result['document']['Name']}\")  \n",
    "    print(f\"Dept: {result['document']['Dept']}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complete') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
